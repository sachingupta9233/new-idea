{
  "_duxport_model_version": "2.0",
  "format": "pkl",
  "model_info": {
    "model_id": "gradient_boost_reg",
    "model_name": "Gradient Boosting Regressor",
    "task_type": "regression",
    "target_column": "actual_price",
    "features": [
      "location",
      "area_sqft",
      "bhk",
      "bathrooms",
      "floor",
      "total_floors",
      "age_of_property",
      "parking",
      "lift"
    ],
    "metrics": {
      "r2_score": 0.8930451993667555,
      "mse": 8612498259958.135,
      "rmse": 2934705.821706519,
      "mae": 2206216.299763917
    },
    "feature_importance": [
      {
        "name": "area_sqft",
        "importance": 0.6376092304319502
      },
      {
        "name": "age_of_property",
        "importance": 0.09420255236565023
      },
      {
        "name": "total_floors",
        "importance": 0.08009800458882774
      },
      {
        "name": "bhk",
        "importance": 0.07517609660351596
      },
      {
        "name": "floor",
        "importance": 0.0547513985262873
      },
      {
        "name": "location",
        "importance": 0.03579803663048935
      },
      {
        "name": "bathrooms",
        "importance": 0.014340289180806423
      },
      {
        "name": "lift",
        "importance": 0.006668069833392414
      },
      {
        "name": "parking",
        "importance": 0.0013563218390804598
      }
    ],
    "training_time_ms": 7251
  },
  "configuration": {
    "epochs": 25,
    "learning_rate": 0.01,
    "batch_size": 32,
    "test_split": 20
  },
  "dataset_info": {
    "rows": 2450,
    "columns": 10,
    "file_name": "navi_mumbai_real_estate_uncleaned_2500_cleaned.csv"
  },
  "all_model_results": [
    {
      "model_id": "gradient_boost_reg",
      "model_name": "Gradient Boosting Regressor",
      "metrics": {
        "r2_score": 0.8930451993667555,
        "mse": 8612498259958.135,
        "rmse": 2934705.821706519,
        "mae": 2206216.299763917
      },
      "feature_importance": [
        {
          "name": "area_sqft",
          "importance": 0.6376092304319502
        },
        {
          "name": "age_of_property",
          "importance": 0.09420255236565023
        },
        {
          "name": "total_floors",
          "importance": 0.08009800458882774
        },
        {
          "name": "bhk",
          "importance": 0.07517609660351596
        },
        {
          "name": "floor",
          "importance": 0.0547513985262873
        },
        {
          "name": "location",
          "importance": 0.03579803663048935
        },
        {
          "name": "bathrooms",
          "importance": 0.014340289180806423
        },
        {
          "name": "lift",
          "importance": 0.006668069833392414
        },
        {
          "name": "parking",
          "importance": 0.0013563218390804598
        }
      ],
      "training_time_ms": 7251
    },
    {
      "model_id": "random_forest_reg",
      "model_name": "Random Forest Regressor",
      "metrics": {
        "r2_score": 0.49919307353931197,
        "mse": 40327304218049.25,
        "rmse": 6350378.273618765,
        "mae": 4524930.385950445
      },
      "feature_importance": [
        {
          "name": "area_sqft",
          "importance": 0.2372494408225309
        },
        {
          "name": "age_of_property",
          "importance": 0.18349609931047325
        },
        {
          "name": "floor",
          "importance": 0.10797429016067793
        },
        {
          "name": "total_floors",
          "importance": 0.10514984647434357
        },
        {
          "name": "bathrooms",
          "importance": 0.0999479880120097
        },
        {
          "name": "bhk",
          "importance": 0.09635925720864695
        },
        {
          "name": "location",
          "importance": 0.0941863014216986
        },
        {
          "name": "lift",
          "importance": 0.04496869464207438
        },
        {
          "name": "parking",
          "importance": 0.030668081947544775
        }
      ],
      "training_time_ms": 1724
    },
    {
      "model_id": "neural_net_reg",
      "model_name": "Neural Network (MLP)",
      "metrics": {
        "r2_score": 0.8634790165542436,
        "mse": 10993304885922.844,
        "rmse": 3315615.3103040834,
        "mae": 2620451.9888867713
      },
      "feature_importance": [
        {
          "name": "area_sqft",
          "importance": 0.2372494408225309
        },
        {
          "name": "age_of_property",
          "importance": 0.18349609931047325
        },
        {
          "name": "floor",
          "importance": 0.10797429016067793
        },
        {
          "name": "total_floors",
          "importance": 0.10514984647434357
        },
        {
          "name": "bathrooms",
          "importance": 0.0999479880120097
        },
        {
          "name": "bhk",
          "importance": 0.09635925720864695
        },
        {
          "name": "location",
          "importance": 0.0941863014216986
        },
        {
          "name": "lift",
          "importance": 0.04496869464207438
        },
        {
          "name": "parking",
          "importance": 0.030668081947544775
        }
      ],
      "training_time_ms": 64541
    }
  ],
  "python_reconstruction_script": "\"\"\"\nAuto-generated by Duxport ML Dashboard\nReconstructs the trained model in scikit-learn and saves as .pkl / .joblib\n\nUsage:\n  pip install scikit-learn pandas numpy joblib\n  python load_model.py\n\"\"\"\n\nimport json\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nimport joblib\nimport pickle\n\n# ── Configuration ──\nTASK_TYPE = \"regression\"\nTARGET_COLUMN = \"actual_price\"\nFEATURES = [\"location\",\"area_sqft\",\"bhk\",\"bathrooms\",\"floor\",\"total_floors\",\"age_of_property\",\"parking\",\"lift\"]\nBEST_MODEL = \"gradient_boost_reg\"\nTEST_SPLIT = 0.2\n\n# Best model metrics from browser training:\n# r2_score: 0.8930, mse: 8612498259958.1348, rmse: 2934705.8217, mae: 2206216.2998\n\nprint(f\"Setting up {BEST_MODEL} for {TASK_TYPE} task...\")\nprint(f\"Target: {TARGET_COLUMN}, Features: {len(FEATURES)}\")\n\n\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neural_network import MLPRegressor\n\nMODELS = {\n    \"linear_regression\": LinearRegression(),\n    \"ridge_regression\": Ridge(alpha=1.0),\n    \"decision_tree_reg\": DecisionTreeRegressor(max_depth=10, random_state=42),\n    \"random_forest_reg\": RandomForestRegressor(n_estimators=100, random_state=42),\n    \"gradient_boost_reg\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n    \"knn_reg\": KNeighborsRegressor(n_neighbors=5),\n    \"svr\": SVR(),\n    \"neural_net_reg\": MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=25, random_state=42),\n}\n\n# Load your CSV:\ndf = pd.read_csv(\"navi_mumbai_real_estate_uncleaned_2500_cleaned.csv\")\nX = df[FEATURES]\ny = df[TARGET_COLUMN]\n\n# Encode categoricals\nfor col in X.select_dtypes(include=['object']).columns:\n    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n\n\n# Scale features\nscaler = StandardScaler()\nX = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=42)\n\n# Train the best model\nmodel = MODELS.get(BEST_MODEL, list(MODELS.values())[0])\nprint(f\"\\nTraining {model.__class__.__name__}...\")\nmodel.fit(X_train, y_train)\nscore = model.score(X_test, y_test)\nprint(f\"Test Score: {score:.4f}\")\n\n# Save as .pkl\nwith open(\"model.pkl\", \"wb\") as f:\n    pickle.dump({\"model\": model, \"scaler\": scaler, \"features\": FEATURES, \"target\": TARGET_COLUMN}, f)\nprint(\"Saved: model.pkl\")\n\n# Save as .joblib\njoblib.dump({\"model\": model, \"scaler\": scaler, \"features\": FEATURES, \"target\": TARGET_COLUMN}, \"model.joblib\")\nprint(\"Saved: model.joblib\")\n\nprint(\"\\nDone! Load with: pickle.load(open('model.pkl','rb')) or joblib.load('model.joblib')\")\n",
  "exported_at": "2026-02-23T10:26:26.748Z",
  "_note": "This is a Duxport model package. Use the included python_reconstruction_script to reconstruct a scikit-learn model from your CSV data."
}